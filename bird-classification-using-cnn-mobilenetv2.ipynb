{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ü¶úBird Classification using Deep Convolutional Neural Networks and Transfer Learning\n\n<center><img src='https://media2.giphy.com/media/SvuYYhf9IuL1fEXq4q/200w.webp?cid=ecf05e47xxpr49vt9ioo8yv14ilsi660fz5fimac7c7thctk&rid=200w.webp&ct=s' height=150px width=200px></center>\n\n## üî¨Overview \nWildlife conservation has been recently transformed by the application of artificial intelligence. AI helps researchers determine the location of animals, date of sighting, migration patterns, and even an animal social group. AI is used by conservationists to monitor and protect animals in their natural habitat.\n\nThere are an estimated 30,000 threatened species across the globe. Scientists are utilizing AI to understand what put these species at risk by offering information about where they are born, how many survive, where they go, and how far they go. Following are some advantages of AI in the conservation of animal species:\n\n* AI facilitates the collection of vast and fascinating datasets and their analysis in no time.\n* AI is helping wildlife researchers in studying the wild animal species collectively and making strategies to protect them.\n* Artificial intelligence tracks wildlife patterns and predicts the extinction of endangered animal species.\n* It helps conservationists to detect and stop wildlife poaching.\n* It can provide information about the effects of climate change on wildlife and reducing its impact by designing a proper plan.\n* AI assists in assessing the species population and see changes.\n* It helps to stop illegal animal trade on social media.\n* Artificial intelligence identifies and classifies animal species into various classes and provides detailed information about them.\n* AI algorithms can conserve animal habitats by predicting animal migratory patterns.\n[Source](https://aiworldschool.com/research/this-is-why-ai-in-wildlife-conservation-is-so-glorious/)\n\n## ‚ùóAuthor's Note:\nMake sure to run the cells from top to bottom with a GPU accelerator. There are some linux commands present in some cells so this is important to take into account. Also, any suggestions, comments and recommendations to improve the notebook will be highly appreciated. Cheers!\n\n","metadata":{"id":"n6QHvU2dfpFz"}},{"cell_type":"markdown","source":"# üèóÔ∏èImport Necessary Libraries","metadata":{"id":"kQELj5Dwf3on"}},{"cell_type":"code","source":"# Import Data Science Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n# Tensorflow Libraries\nfrom tensorflow import keras\nfrom tensorflow.keras import layers,models\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# System libraries\nfrom pathlib import Path\nimport os.path\n\n# Metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools","metadata":{"id":"lEzJXgjDf5y8","execution":{"iopub.status.busy":"2022-08-28T04:29:41.849977Z","iopub.execute_input":"2022-08-28T04:29:41.851931Z","iopub.status.idle":"2022-08-28T04:29:48.893759Z","shell.execute_reply.started":"2022-08-28T04:29:41.851843Z","shell.execute_reply":"2022-08-28T04:29:48.892752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ü§ôCreate helper functions","metadata":{"id":"D_SnZPRah_9D"}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n\n# Import series of helper functions for our notebook\nfrom helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot","metadata":{"id":"F8ReVC2MiBRZ","outputId":"c53e6082-d883-478d-d42f-887eb8399678","execution":{"iopub.status.busy":"2022-08-28T04:29:48.896105Z","iopub.execute_input":"2022-08-28T04:29:48.897302Z","iopub.status.idle":"2022-08-28T04:29:50.196492Z","shell.execute_reply.started":"2022-08-28T04:29:48.897259Z","shell.execute_reply":"2022-08-28T04:29:50.195295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üì•Load and Transform Data","metadata":{"id":"Hb_XPhOwiCNY"}},{"cell_type":"code","source":"BATCH_SIZE = 32\nIMAGE_SIZE = (300, 300)","metadata":{"id":"8nD56d7Xxmc3","execution":{"iopub.status.busy":"2022-08-28T04:29:50.198359Z","iopub.execute_input":"2022-08-28T04:29:50.1997Z","iopub.status.idle":"2022-08-28T04:29:50.204984Z","shell.execute_reply.started":"2022-08-28T04:29:50.199643Z","shell.execute_reply":"2022-08-28T04:29:50.203893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Walk through each directory\ndataset = \"../input/100-bird-species/train\"\nwalk_through_dir(dataset);","metadata":{"id":"5kXkjadNxsNI","outputId":"478c212a-b21e-4e08-e472-9b101759173e","execution":{"iopub.status.busy":"2022-08-28T04:29:50.209076Z","iopub.execute_input":"2022-08-28T04:29:50.209419Z","iopub.status.idle":"2022-08-28T04:30:08.071839Z","shell.execute_reply.started":"2022-08-28T04:29:50.209393Z","shell.execute_reply":"2022-08-28T04:30:08.070761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìÖPlacing data into a Dataframe\nThe first column `filepaths` contains the file path location of each individual images. The second column `labels`, on the other hand, contains the class label of the corresponding image from the file path","metadata":{"id":"MLAnhGlf1hmo"}},{"cell_type":"code","source":"image_dir = Path(dataset)\n\n# Get filepaths and labels\nfilepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))\n\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\n# Concatenate filepaths and labels\nimage_df = pd.concat([filepaths, labels], axis=1)","metadata":{"id":"s14XOEp01m_s","execution":{"iopub.status.busy":"2022-08-28T04:30:08.073471Z","iopub.execute_input":"2022-08-28T04:30:08.073862Z","iopub.status.idle":"2022-08-28T04:30:10.745879Z","shell.execute_reply.started":"2022-08-28T04:30:08.073824Z","shell.execute_reply":"2022-08-28T04:30:10.744844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_df","metadata":{"id":"d3-uoP4n1oqK","outputId":"4af0c4a5-c87d-42eb-aa1b-fe89f1fe8876","execution":{"iopub.status.busy":"2022-08-28T04:30:10.747575Z","iopub.execute_input":"2022-08-28T04:30:10.747978Z","iopub.status.idle":"2022-08-28T04:30:10.771168Z","shell.execute_reply.started":"2022-08-28T04:30:10.747939Z","shell.execute_reply":"2022-08-28T04:30:10.770078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üî≠Visualizing images from the dataset","metadata":{"id":"agb1QMDO1pps"}},{"cell_type":"code","source":"# Display 16 picture of the dataset with their labels\nrandom_index = np.random.randint(0, len(image_df), 16)\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n    ax.set_title(image_df.Label[random_index[i]])\nplt.tight_layout()\nplt.show()","metadata":{"id":"m4WJVJ7j1rU9","outputId":"777f0f9a-e46c-4475-ca6a-97a4e6fb89a3","execution":{"iopub.status.busy":"2022-08-28T04:30:10.772589Z","iopub.execute_input":"2022-08-28T04:30:10.773045Z","iopub.status.idle":"2022-08-28T04:30:11.929117Z","shell.execute_reply.started":"2022-08-28T04:30:10.77301Z","shell.execute_reply":"2022-08-28T04:30:11.928248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìùData Preprocessing\nThe data will be split into three different categories: Training, Validation and Testing. The training data will be used to train the deep learning CNN model and its parameters will be fine tuned with the validation data. Finally, the performance of the data will be evaluated using the test data(data the model has not previously seen).","metadata":{"id":"YwC4EWei1s-V"}},{"cell_type":"code","source":"# Separate in train and test data\ntrain_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)","metadata":{"id":"xaJlHTlz2K4M","execution":{"iopub.status.busy":"2022-08-28T04:30:11.930045Z","iopub.execute_input":"2022-08-28T04:30:11.930345Z","iopub.status.idle":"2022-08-28T04:30:11.950003Z","shell.execute_reply.started":"2022-08-28T04:30:11.930316Z","shell.execute_reply":"2022-08-28T04:30:11.949241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntest_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","metadata":{"id":"3puUVDwl2Mcz","execution":{"iopub.status.busy":"2022-08-28T04:30:11.951308Z","iopub.execute_input":"2022-08-28T04:30:11.951922Z","iopub.status.idle":"2022-08-28T04:30:11.957934Z","shell.execute_reply.started":"2022-08-28T04:30:11.951884Z","shell.execute_reply":"2022-08-28T04:30:11.956666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into three categories.\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","metadata":{"id":"CsftNShQ2PaK","outputId":"ee3c99b5-3932-4187-f600-1e86cf334026","execution":{"iopub.status.busy":"2022-08-28T04:30:11.963231Z","iopub.execute_input":"2022-08-28T04:30:11.963965Z","iopub.status.idle":"2022-08-28T04:30:51.839179Z","shell.execute_reply.started":"2022-08-28T04:30:11.963931Z","shell.execute_reply":"2022-08-28T04:30:51.838142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resize Layer\nresize_and_rescale = tf.keras.Sequential([\n  layers.experimental.preprocessing.Resizing(224,224),\n  layers.experimental.preprocessing.Rescaling(1./255),\n])","metadata":{"id":"sLbR4WtD2RPg","execution":{"iopub.status.busy":"2022-08-28T04:30:51.840731Z","iopub.execute_input":"2022-08-28T04:30:51.841341Z","iopub.status.idle":"2022-08-28T04:30:54.807916Z","shell.execute_reply.started":"2022-08-28T04:30:51.841302Z","shell.execute_reply":"2022-08-28T04:30:54.806648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ü§πTraining the model\nThe model images will be subjected to a pre-trained CNN model called MobileNetV2. Three callbacks will be utilized to monitor the training. These are: Model Checkpoint, Early Stopping, Tensorboard callback. The summary of the model hyperparameter is shown as follows:\n\n**Batch size** : 32\n\n**Epochs** : 100\n\n**Input Shape** : (224, 224, 3)\n\n**Output layer** : 400\n\n","metadata":{"id":"xSEhK2w02Uk-"}},{"cell_type":"code","source":"# Load the pretained model\npretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","metadata":{"id":"z4VI_UxV2Wp2","execution":{"iopub.status.busy":"2022-08-28T04:30:54.80954Z","iopub.execute_input":"2022-08-28T04:30:54.809937Z","iopub.status.idle":"2022-08-28T04:30:55.988656Z","shell.execute_reply.started":"2022-08-28T04:30:54.8099Z","shell.execute_reply":"2022-08-28T04:30:55.98769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create checkpoint callback\ncheckpoint_path = \"birds_classification_model_checkpoint\"\ncheckpoint_callback = ModelCheckpoint(checkpoint_path,\n                                      save_weights_only=True,\n                                      monitor=\"val_accuracy\",\n                                      save_best_only=True)","metadata":{"id":"1xn6j_La2Y2u","execution":{"iopub.status.busy":"2022-08-28T04:30:55.990019Z","iopub.execute_input":"2022-08-28T04:30:55.990371Z","iopub.status.idle":"2022-08-28T04:30:55.995862Z","shell.execute_reply.started":"2022-08-28T04:30:55.990336Z","shell.execute_reply":"2022-08-28T04:30:55.994884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\nearly_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n                               patience = 5,\n                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training","metadata":{"id":"YbP7g6Xh2abB","execution":{"iopub.status.busy":"2022-08-28T04:30:55.997371Z","iopub.execute_input":"2022-08-28T04:30:55.998036Z","iopub.status.idle":"2022-08-28T04:30:56.009771Z","shell.execute_reply.started":"2022-08-28T04:30:55.998Z","shell.execute_reply":"2022-08-28T04:30:56.008826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üöÑTraining the model","metadata":{"id":"alynENS02jm4"}},{"cell_type":"code","source":"inputs = pretrained_model.input\nx = resize_and_rescale(inputs)\n\nx = Dense(256, activation='relu')(pretrained_model.output)\nx = Dropout(0.2)(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.2)(x)\n\n\noutputs = Dense(400, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer=Adam(0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    steps_per_epoch=len(train_images),\n    validation_data=val_images,\n    validation_steps=len(val_images),\n    epochs=100,\n    callbacks=[\n        early_stopping,\n        create_tensorboard_callback(\"training_logs\", \n                                    \"bird_classification\"),\n        checkpoint_callback,\n    ]\n)","metadata":{"id":"AkcAsl5H2tYl","outputId":"173d8e87-7f30-401e-fe3b-077c21025b59","execution":{"iopub.status.busy":"2022-08-28T05:12:53.672162Z","iopub.execute_input":"2022-08-28T05:12:53.672899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚úîÔ∏èModel Evaluation\nThe test dataset will be used to evaluate the performance of the model.One of the metrics that will be tested would be accuracy which measures the fraction of predictions the model got right. Other metrics are as follows:\n\n**Precision(P)**: \nThe fraction of true positives (TP, correct predictions) from the total amount of relevant results, i.e., the sum of TP and false positives (FP). For multi-class classification problems, P is averaged among the classes. The following is the formula for precision.\n\n<center>$P=TP/(TP+FP)$</center>\n\n**Recall(R)**: \nThe fraction of TP from the total amount of TP and false negatives (FN). For multi-class classification problems, R gets averaged among all the classes. The following is the formula for recall.\n<center>$R=TP/(TP+FN)$</center>\n\n**F1 score(F1)**: \nThe harmonic mean of precision and recall. For multi-class classification problems, F1 gets averaged among all the classes. The following is the formula for F1 score.\n<center>$F1=2 * (TP * FP)/(TP+FP)$</center>\n\n","metadata":{"id":"_BWrofxS2vO0"}},{"cell_type":"code","source":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"id":"CS-g90hJ340B","outputId":"8b35403d-9dc0-4a65-b08e-ce223aef2bdb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìâVisualizing loss curves","metadata":{"id":"t5oGHvsG368q"}},{"cell_type":"code","source":"plot_loss_curves(history)","metadata":{"id":"01SS6RVx38o7","outputId":"f982ac64-9de4-4306-c917-1b7a1d0f6e06","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üîÆMaking predictions on the Test Data","metadata":{"id":"0BL7xgPz4Fv-"}},{"cell_type":"code","source":"# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\n# Display the result\nprint(f'The first 5 predictions: {pred[:5]}')","metadata":{"id":"KxAegJBB4HlW","outputId":"c836256c-be8e-4346-b6c2-d4c39d030db4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  # Display 25 random pictures from the dataset with their labels\nrandom_index = np.random.randint(0, len(test_df) - 1, 15)\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n      color = \"green\"\n    else:\n      color = \"red\"\n    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\nplt.show()\nplt.tight_layout()","metadata":{"id":"pWO4e4wb4Iln","outputId":"a58f3382-f991-43ac-e54f-6bd9a36dd25f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìäPlotting the Classification Reports and Confusion Matrix","metadata":{"id":"jLYd5vYJ4KTu"}},{"cell_type":"code","source":"y_test = list(test_df.Label)\nprint(classification_report(y_test, pred))","metadata":{"id":"6ySAZoU74MlB","outputId":"b4c6bf97-d4b1-4def-d1a8-bb79c9685504","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = classification_report(y_test, pred, output_dict=True)\ndf = pd.DataFrame(report).transpose()\ndf","metadata":{"id":"bYWvkbXI4Ns2","outputId":"7e04d8a2-3263-4a31-d469-70d8140cb167","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"PGvdcGEI4RCb"},"execution_count":null,"outputs":[]}]}